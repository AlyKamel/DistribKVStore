\section{Key-value server}
During the first four milestones, we were tasked with developing a distributed key-value storage system, which includes many features such as replication and caching. In this section, we focus on the implementation behind some of those properties.

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{figures/kvserver/ms4_structure.png}
	\caption{KV server architecture}
\end{figure}




\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{figures/kvserver/kvs_arch.png}
	\caption{Client side architecture}
\end{figure}


--> Implementation moved here

In this section the implementation of the chatroom is examined in depth. Firstly, the extension for the client side and then for the server side are described respectively. Lastly the chat system is explained in greater detail, since it encapsulates our work for Milestone 5.

\subsection{Client Side Implementation}
\label{sec:Implementation_clintside}

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{figures/kvserver/client_arch.png}
	\caption{Client side architecture}
	\label{fig:client_arch}
\end{figure}
The client side consists of the three following main components as seen in figure \ref{fig:client_arch}:
\begin{enumerate} 
  \item \textit{ClientApp} represents the client interface which allows input through the console. From there the client is able to issue commands to: connect to and disconnect from the system, interact with the key-value store and chat. The input is then checked and parsed before getting sent to the ClientLibrary. The result of the user command is displayed on the console through the ClientApp.
  \item \textit{ClientLibrary} serves as a bridge between the client and the server.
  \item \textit{ActiveConnection} abstracts the TCP socket connection to the server which allows the client to connect to the server socket and exchange data without worrying about the underlying structure.
\end{enumerate}
 
\subsection{Server Side Implementation}
\label{sec:implementation_serverside}

Each server owns a list containing the active chatrooms that it is responsible for. In order for a client to join one of those chatrooms is that it would first need to connect to that server, similar to the way storing key-value pair functions. The decision, to make chatrooms accessible only from one server has both its advantages and disadvantages. For one, it reduces the complexity of the system because otherwise servers would need a way to exchange updates regarding the active chatrooms and chat users whenever a user joins or leaves.

A problem with our implementation is that if the chatIDs are not equally distributed across all servers, which may occur due to the unpredictable nature of the hashing function, a single server could then be in charge of most chatrooms. This would cause that a server to be overloaded with requests and would lead to greater response times and, in the worst-case scenario, would result in a bottleneck for the whole system. In order to combat this issue, we limit the number of chatrooms belonging to one server to 15 and the number of users in a single chatroom to 30. This means a server is responsible for up to 450 chat users. These limits could also be easily changed depending on the intended use case of the system.

The biggest advantage of our decision is that it heavily reduces network traffic. Since all chatroom users are connected to the same server, that server can easily forward messages between them. Otherwise additional socket connections would have been required which would have both increased the load on the network and the overall complexity of the system.

Our idea for the chatting functionality was for it to be as lightweight as possible with clients entering and leaving chatrooms regularly.

server side:
The client interacts directly only with the ConnectionHandleThread (CHT) created by the server to assist that specific client. At the start of the connection, the CHT contacts the ECS in order to assign the client a unique username. After that the CHT interacts exclusively with KV storage and the chat system, depending on the command issued by the client. The KV storage system provides the basic capabilities of a key-value store and persists data on disk. When more than two servers are online and replication is active, each server contains a replica of two other servers. Whenever a put operation is executed, it has to get forwarded to the server.

kv storage:
The KVCommandProcessor (KVCP) is responsible to receive commands from the CHT and return the result. Before a value is stored or retrieved, the KVCP utilizes the ServerRing to check whether the server is responsible for the provided key or not. In the latter case, a simple error message is returned back to the client, which would then connect to the responsible server. In the former case, the request is sent over to the KVStore. If it was a GET command issued, the KVStore first tries to retrieve the value from the cache. In case the value has not been found, the DiskStore checks if it is stored on disk.
With a PUT request, the KVStore sends the key-value pair to both the cache and DiskStore and also to the RepManager. This allows it to get sent over to the two replica servers. The RepManager is also charged with updating the replica on the server whenever one of the coordinators processes a PUT command.

